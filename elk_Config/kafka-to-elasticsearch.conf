input {
  kafka {
    bootstrap_servers => "localhost:9092" # Replace with your Kafka broker address
    topics => ["processed-events"]        # Replace with your Kafka topic
#    group_id => "logstash-group"         # Optional: consumer group ID
    codec => "json"                       # Specify the codec if data is in JSON format
  }
}

filter {
  # Optional: Add any data transformation or filtering logic here
  # Example:
  # mutate {
  #   rename => { "field1" => "new_field1" }
  # }
}

#output {
#  elasticsearch {
#    hosts => ["http://localhost:9200"]    # Replace with your Elasticsearch URL
#    index => "processed-events-index"     # Replace with your desired index name
#    document_id => "%{id}"               # Optional: Use a unique field as document ID
#	document_id => "%{[eventId]}"         # Unique ID for deduplication
#  }

  # Optional: Debugging output
#  stdout {
#    codec => rubydebug
#  }
#}

output {
  elasticsearch {
    hosts => ["https://localhost:9200"]
    user => "elastic"
    password => "Z9Ei3Etp-LYD4Ll*IsGs"
    ssl => true
    cacert => "C:/elastic-stack/elasticsearch-8.17.0/config/certs/http_ca.crt" # Path to the CA certificate
  }
}